{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting Grandmasters\n",
    "## Volume 3 Math 402 Final Project\n",
    "\n",
    "### Damian and Whitney Anderson,\n",
    "### Nathan Christiansen, Reagan Howell\n",
    "\n",
    "#### Date 11/16/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Introduction\n",
    "Have you ever started playing a game of chess online and wondered if your opponent was one of the top players on lichess.org?\n",
    "\n",
    "We have ... well, not really, but we were wondering how accurately could you predict your chess opponent based on the moves that they make.\n",
    "In the past, chess opening moves were studied to find the move order that would give the\n",
    "\n",
    "So taking the top ~30 players on lichess.org and downloading their classical and rapid format (>25 min and >10 min respectively) games.\n",
    "With their games in what would it take to help us understand the patterns that these masters are making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Importing, Parsing and Cleaning the Data\n",
    "\n",
    "All games were downloaded from lichess.org open database using links like this\n",
    "\n",
    "https://lichess.org/api/games/user/Al_shima?rated=true&analysed=true&tags=true&clocks=true&evals=false&opening=false&perfType=rapid\n",
    "\n",
    "The using regex to remove any of the unimportant information and stripping the .txt files to get the chess game Portable Game Notation (pgn) and the moves that were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, regex as re, numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression,LogisticRegressionCV,Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The main function utilizes the create_database() function to access the data files and build our DataFrame. We create a\n",
    "DataFrame with columns for the players' name, color they were playing as, the variant, and the first 14 moves they make\n",
    "in their game. We then import that Dataframe into chess_games.csv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creating the X-data and the y-targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load chess_games.csv and break it into the data and the targets. We hope to predict the name of the Grandmaster\n",
    "playing the game, so we choose the name column as our targets. We are using the first 14 moves the player makes in order\n",
    "to predict who is playing, so our data is the 14 columns of moves from each game. We create a train/test split of .75\n",
    "training and .25 testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Approach\n",
    "If we just guessed the player with the most games, Rochade_Augsburg, our model would be right 40.73% of the time. So any model that we make should be able to beat this average. \n",
    "We started by just taking our train_test_split data and throwing it into all the reasonable machine learning models without any conditions on it. As a baseline measurement we took the mode of the all the players and divided it by the total number of games. \n",
    "Running a K-Nearest Neighbors, Multinomial Naive Bayes, a Random Forest, and a MultiLayer Perceptron Classifier, these are their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_():\n",
    "    df = pd.read_csv(\"chess_games.csv\")\n",
    "    targets = df.Name\n",
    "    data = df.drop(columns=['Name', 'Color', 'Variant', 'Moves'])\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def sets_():\n",
    "    data, targets = load_()\n",
    "    data = pd.get_dummies(data,columns=data.columns)\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(data,targets)\n",
    "    return xtrain,xtest,ytrain,ytest\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = sets_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline is 0.4072910119421747 which we get by guessing Rochade_Augsburg.\n"
     ]
    }
   ],
   "source": [
    "def generate_baseline(ytrain,ytest):\n",
    "    best_guess = mode(ytrain)\n",
    "    baseline = sum(ytest == best_guess) / len(ytest)\n",
    "    return baseline, best_guess\n",
    "print(\"Our baseline is {} which we get by guessing {}.\".format(*generate_baseline(ytrain,ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have split the data, we use several classifiers with some adjustments to hyper-parameters to figure out\n",
    "which combination gives us the most accurate prediction of the Grandmaster playing any given game. In order to make\n",
    "sure that no classifier got a better split than the others, we (begrudgingly) made the xtrain, xtest, ytrain, and ytest \n",
    "variables global and accessible to any function or method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier\n",
    "K Nearest Neighbors\n",
    "\n",
    "After doing a lot of Grid Searching by \"hand\", we found this that looking at the 4 nearest neighbors, \n",
    "using a distance metric and jst the brute force algorithm resulted in the fastest and highest scoring model type.\n",
    "\n",
    "%n_neighbors=4,weights='distance',algorithm='brute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6272784412319296"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier().fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228786926461345"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().fit(xtrain,ytrain).score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6209930861093652"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(xtrain,ytrain).score(xtest,ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6323067253299811"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPClassifier(hidden_layer_sizes=(50,)).fit(xtrain,ytrain).score(xtest,ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Move Order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New data cleaning fucntions\n",
    "def create_database():\n",
    "    \"\"\"\n",
    "    Calls the files, get_games functions to creates a dataframe\n",
    "    Returns a dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    file, players = files()\n",
    "    df = []\n",
    "    for i in range(len(players)):\n",
    "        #create a list of all the files and their corresponding players and then input that list into the DataFrame\n",
    "        df.extend(get_games(path + '/' + file[i], players[i]))\n",
    "    df = pd.DataFrame(df, columns=['Name', 'Color', 'Variant', 'Moves'])\n",
    "    df = df[df['Variant'] == 'Standard']\n",
    "    \n",
    "    # shift moves\n",
    "    pattern = re.compile(r\"( [0-9]+.)( \\S+)\")\n",
    "    for i,m in enumerate(df.Moves):\n",
    "        if df.iloc[i].Color=='Black':\n",
    "            new = pattern.sub(r\"\\2\\1\",' '+m)\n",
    "            df.iloc[i].Moves = new[new.find('1'):]\n",
    "    \n",
    "    return df\n",
    "def load_():\n",
    "    df = pd.read_csv(\"chess_games.csv\")\n",
    "    targets = df.Name\n",
    "    data = df.drop(columns=['Name', 'Color', 'Variant', 'Moves'])\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def sets_():\n",
    "    data, targets = load_()\n",
    "    data = pd.get_dummies(data,columns=data.columns)\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(data,targets)\n",
    "    # params = {'n_neighbors': [2,3,4],\n",
    "    #         'weights' :['uniform','distance'],\n",
    "    #         'leaf_size' : [30,40,50,60],\n",
    "    #\n",
    "    # }\n",
    "    return xtrain,xtest,ytrain,ytest\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = sets_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6499057196731616"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier(n_neighbors=4,weights='distance',algorithm='brute').fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6197360150848523"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB().fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6209930861093652"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPClassifier(hidden_layer_sizes=(50,)).fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5801382778126964"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB().fit(xtrain,ytrain).score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Splitting on color\n",
    "Each of the classifiers gives us about a 60-65% confidence rate in predicting the Grandmaster that we are playing against in any given game. Given that this is from a set of 27 Grandmasters, that means that just a random guess would be correct about 3-4 percent of the time, we feel that this is a pretty good algorithm for prediction.\n",
    "Next, we will adjust the way that we organize our data. We know that in a game of chess, whether you are playing as white or black vastly changes the sort of strategy that one employs, white being more offensive and black being more defensive. So we will split the data into two databases, separating them based on whether they are playing as black or as white. This may give us a better prediction model as well.\n",
    "Again, we will try several different classifiers to score our prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the White and black data sets\n",
    "def load_():\n",
    "    df = pd.read_csv(\"chess_games.csv\")\n",
    "    targets = df.Name\n",
    "    data = df.drop(columns=['Name', 'Variant', 'Moves'])\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def sets_():\n",
    "    data, targets = load_()\n",
    "    cols = list(data.columns).remove(\"Color\")\n",
    "    data = pd.get_dummies(data,columns=cols)\n",
    "    xtrain0,xtest0,ytrain0,ytest0 = train_test_split(data[data['Color_White']==0],targets[data['Color_White']==0])\n",
    "    xtrain1,xtest1,ytrain1,ytest1 = train_test_split(data[data['Color_White']==1],targets[data['Color_White']==1])\n",
    "\n",
    "    xtrain0.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtest0.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtrain1.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtest1.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "\n",
    "    return xtrain0,xtest0,ytrain0,ytest0,xtrain1,xtest1,ytrain1,ytest1\n",
    "\n",
    "xtrain0,xtest0,ytrain0,ytest0,xtrain1,xtest1,ytrain1,ytest1 = sets_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9886363636363636"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "KNeighborsClassifier(n_neighbors=4,weights='distance',algorithm='brute').fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9965277777777778"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "KNeighborsClassifier(n_neighbors=4,weights='distance',algorithm='brute').fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5409090909090909"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "MultinomialNB().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3515625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "MultinomialNB().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7977272727272727"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "RandomForestClassifier().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7465277777777778"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "RandomForestClassifier().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Black Score')\n",
    "MLPClassifier().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('White Score')\n",
    "MLPClassifier().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3159090909090909"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "GaussianNB().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('White Score')\n",
    "GaussianNB().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Why is the K Nearest Neighbors classifier working so well compared to the other classifiers?\n",
    "K Nearest Neighbors works by looking at the given row of data, and finding the K rows of data that are most similar to the given row. The label that is most common in those K “Nearest Neighbors” is the label that is chosen to classify the given row of data. In our data, this corresponds to looking at the first 15 moves of the given game, and finding games where the first 15 moves were very similar. As with any sort of game involving strategy, people who play the game will find their style of play and regularly fall back on the same moves that are often successful for them. So given a game played by a certain Grandmaster, the games with the most similar moves will be played by themselves, and thus the K Nearest Neighbors classifier was able to recognize the person who played the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing a Player\n",
    "\n",
    "As data scientists, we have learned to not really trust data. Therefore, we are astounded and amazed at the accuracy of our predicter. We do recognize that over half of our data is games played by one player, Rochade_Augsburg, which could be skewing the accuracy of the predicter by having such a common name to guess. In an attempt to gut check our predicter, we have built a new database with all of Rochade_Augsburg's data removed, so that we can confirm that our predictor is accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_():\n",
    "    df = pd.read_csv(\"chess_games.csv\")\n",
    "    targets = df.Name\n",
    "    df,targets = df[df[\"Name\"]!=\"Rochade_Augsburg\"],targets[df[\"Name\"]!=\"Rochade_Augsburg\"]\n",
    "    data = df.drop(columns=['Name', 'Variant', 'Moves'])\n",
    "    \n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def sets_():\n",
    "    data, targets = load_()\n",
    "#     print(data['Unnamed: 0'])\n",
    "#     print(len(data[data['Unnamed: 0']!=\"Rochade_Augsburg\"]))\n",
    "#     data,targets = data[data[\"Name\"]!=\"Rochade_Augsburg\"],targets[data[\"Name\"]!=\"Rochade_Augsburg\"]\n",
    "    cols = list(data.columns).remove(\"Color\")\n",
    "    data = pd.get_dummies(data,columns=cols)\n",
    "    xtrain0,xtest0,ytrain0,ytest0 = train_test_split(data[data['Color_White']==0],targets[data['Color_White']==0])\n",
    "    xtrain1,xtest1,ytrain1,ytest1 = train_test_split(data[data['Color_White']==1],targets[data['Color_White']==1])\n",
    "\n",
    "    xtrain0.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtest0.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtrain1.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "    xtest1.drop(columns=['Color_White','Color_Black'],inplace=True)\n",
    "\n",
    "    return xtrain0,xtest0,ytrain0,ytest0,xtrain1,xtest1,ytrain1,ytest1\n",
    "\n",
    "xtrain0,xtest0,ytrain0,ytest0,xtrain1,xtest1,ytrain1,ytest1 = sets_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our new white baseline is 0.09825033647375504 which we get by guessing kc6.\n"
     ]
    }
   ],
   "source": [
    "print(\"Our new white baseline is {} which we get by guessing {}.\".format(*generate_baseline(ytrain1,ytest1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our new black baseline is 0.36585365853658536 which we get by guessing kc6.\n"
     ]
    }
   ],
   "source": [
    "print(\"Our new black baseline is {} which we get by guessing {}.\".format(*generate_baseline(ytrain0,ytest0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.975609756097561"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "KNeighborsClassifier(n_neighbors=4,weights='distance',algorithm='brute').fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9932705248990579"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "KNeighborsClassifier(n_neighbors=4,weights='distance',algorithm='brute').fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MultinomialNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.22439024390243903"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "MultinomialNB().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.07537012113055182"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "MultinomialNB().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6829268292682927"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Black Score')\n",
    "RandomForestClassifier().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Score\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6958277254374159"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('White Score')\n",
    "RandomForestClassifier().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLPClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Score\n"
     ]
    }
   ],
   "source": [
    "print('Black Score')\n",
    "MLPClassifier().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('White Score')\n",
    "MLPClassifier().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Black Score')\n",
    "GaussianNB().fit(xtrain0,ytrain0).score(xtest0,ytest0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('White Score')\n",
    "GaussianNB().fit(xtrain1,ytrain1).score(xtest1,ytest1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}